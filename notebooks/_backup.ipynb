{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b7514c-fd1d-471f-9d10-3c5e3434cf16",
   "metadata": {},
   "source": [
    "# II. Time Series Models: Theory and Foundations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2f53d-ebc5-4dac-a97d-96683028e4c8",
   "metadata": {},
   "source": [
    "## II.1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8588552-5ff8-442b-b22f-be25330bffef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### II.1.A. What's forecasting about?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7edc1-cf75-4be0-a7ab-e195a87c423b",
   "metadata": {},
   "source": [
    "Forecasting involves the prediction of some future event.\n",
    "\n",
    "Forecasting problems are commonly classified based on the time horizon of the prediction:\n",
    "\n",
    "-   **Short-term forecasting**: This involves predictions a few time periods (days, weeks, or months) into the future.\n",
    "\n",
    "-   **Medium-term forecasting**: This type of forecasting typically covers a horizon from one to two years into the future.\n",
    "\n",
    "-   **Long-term forecasting**: Long-term forecasting extends to predictions many years into the future.\n",
    "\n",
    "Short-term and medium-term forecasting are typically based on identifying, modeling, and extrapolating patterns found in historical data.\n",
    "\n",
    "Long-term forecasting, in contrast, is often based on expert knowledge and fundamental models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be1416-4f16-4df4-a44c-43547efe18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ExampleDataLoader, plot_series_slice\n",
    "\n",
    "energy = ExampleDataLoader(\"energy\").load().set_index(\"datetime\")\n",
    "\n",
    "energy_yr = plot_series_slice(\n",
    "    energy, \n",
    "    start=\"2024-01-01 00:00:00\", \n",
    "    stop=\"2024-12-31 00:00:00\",\n",
    "    freq=\"h\",    \n",
    "    title=\"day-ahead energy demand (Year)\",\n",
    "    return_data=True,\n",
    ")\n",
    "\n",
    "energy_month = plot_series_slice(\n",
    "    energy, \n",
    "    start=\"2024-05-01 00:00:00\", \n",
    "    stop=\"2024-05-31 00:00:00\",\n",
    "    freq=\"h\",\n",
    "    title=\"day-ahead energy demand (Month)\",\n",
    "    return_data=True,\n",
    ")\n",
    "\n",
    "energy_week = plot_series_slice(\n",
    "    energy, \n",
    "    start=\"2024-02-08 00:00:00\", \n",
    "    stop=\"2024-02-15 00:00:00\",\n",
    "    freq=\"h\",\n",
    "    title=\"day-ahead energy demand (Week)\",\n",
    "    return_data=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c933aa-89ae-4e8c-847f-b0dfd6b06f7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### II.1.B. Objectives of time series analysis & forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22a736-5c87-4b6d-9da5-250fcc1c0f17",
   "metadata": {},
   "source": [
    "- **Describing** the evolution of a time series.\n",
    "\n",
    "- **Modelling** the process that has generated the time series by means of a suitable statistical model.\n",
    "\n",
    "- **Forecasting**/Predicting future values of the time series.\n",
    "\n",
    "- **Control**. Good  forecasts enable the analyst to take actions so as to control a given process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63bd7c4-bd7d-450c-9261-9022ce0e5632",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### II.1.C. Forecasting taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ed7e7-27db-4ab1-ab1a-97a5c7c937f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Forecasting methods can be broadly categorized into two types:\n",
    "\n",
    "- **Quantitative methods**: These methods are employed when sufficient information about the past is available, typically in the form of numerical time series data. They assume that the future will be similar to the past, a concept known as the continuity assumption.\n",
    "\n",
    "- **Qualitative methods**: These methods are used when little or no quantitative information is available. They are based on expert knowledge and judgment; a well-known example is the Delphi method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750812c-7644-48af-b601-b4ff7e12d439",
   "metadata": {},
   "source": [
    "Quantitative models can be further classified into two main types:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34318ad1-9689-48d1-827a-900f17ad7bab",
   "metadata": {},
   "source": [
    "- **Explanatory models**: These models express the variable to be forecast ($y$) as a function of other explanatory variables ($x_1, ..., x_n$) and a noise component.\n",
    "\n",
    "$$\n",
    "y = f(x_1, ..., x_n, \\text{noise})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4465de03-21b8-40f9-bdf6-61780f174d6b",
   "metadata": {},
   "source": [
    "- **Time series models**: These models predict the variable to be forecast ($y_t$) as a function of its own past values ($y_{t-1}, y_{t-2}, ...$) and a noise component, or potentially also incorporating explanatory variables.\n",
    "\n",
    "    $$\n",
    "    y_t = f(y_{t-1}, y_{t-2}, ..., \\text{noise})\n",
    "    $$\n",
    "\n",
    "    or\n",
    "\n",
    "    $$\n",
    "    y_t = f(y_{t-1}, y_{t-2}, ..., x_t, x_{t-1}, x_{t-2}, ..., \\text{noise})\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef970d-b553-4e5c-bee1-3a59551cbe7c",
   "metadata": {},
   "source": [
    "In both explanatory and time series models, the observation ($y$) is considered to be composed of two components:\n",
    "\n",
    "$$\n",
    "\\boxed{\\quad y = \\textbf{pattern} + \\textbf{\\color{red}{noise}}\\quad}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d17dc-595e-4f67-9830-8ccd1a654763",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "-   **pattern** = forecast\n",
    "\n",
    "-   **noise** = uncertainty\n",
    "\n",
    "The objective of forecasting is to separate these two components: to use the pattern for forecasting and to characterize prediction errors using the observed noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221057fd-2f0d-4ddd-948a-65c05994cd6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### I.1.D. Forecast steps (future pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e5b94a-7eed-42dd-8390-25512ebfb06e",
   "metadata": {},
   "source": [
    "The general steps involved in the forecasting process are:\n",
    "\n",
    "1.  **Collect Data**: The foundation of any forecasting endeavor is the acquisition of relevant and high-quality historical data. This may involve gathering data from various sources and ensuring its completeness and accuracy.\n",
    "\n",
    "2.  **Preprocess (Clean) Data**: Time series data often requires careful preprocessing to handle imperfections and inconsistencies.\n",
    "\n",
    "    -   **Missing Values Imputation**: Gaps in the time series must be addressed. Techniques like linear interpolation, mean/median imputation, or more sophisticated methods based on time series characteristics can be employed.\n",
    "\n",
    "    -   **Outlier Detection and Treatment**: Extreme values that deviate significantly from the typical pattern can distort forecasts. Identifying and mitigating the impact of outliers through techniques like moving average smoothing or robust statistical methods is essential.\n",
    "\n",
    "    -   **Data Transformation**: In some cases, transformations such as logarithmic or Box-Cox transformations may be necessary to stabilize the variance or make the time series stationary.\n",
    "\n",
    "    -   **Scaling**: Scaling the data (e.g., using min-max scaling or standardization) can be beneficial for certain modeling techniques, especially neural networks.\n",
    "\n",
    "3.  **Feature Engineering (If Applicable)**: Depending on the forecasting model, creating new features from the existing time series can improve predictive performance.\n",
    "\n",
    "    -   **Lagged Variables**: Including past values of the time series as predictors ($y_{t-1}$, $y_{t-2}$, etc.) is a common and powerful technique.\n",
    "\n",
    "    -   **Rolling Statistics**: Calculating statistics over moving windows (e.g., rolling mean, rolling standard deviation) can capture local trends and variability.\n",
    "\n",
    "    -   **Time-Based Features**: Extracting features related to time (e.g., day of the week, month of the year) can help capture seasonality.\n",
    "\n",
    "4.  **Choose Model**: Selecting an appropriate forecasting model is critical and depends on the characteristics of the data and the forecasting task.\n",
    "\n",
    "    -   Consider factors such as the presence of trends, seasonality, autocorrelation, and the desired forecast horizon.\n",
    "\n",
    "    -   Evaluate a range of models, from simple methods like those discussed earlier (average, naive, seasonal naive, drift) to more complex approaches like ARIMA, exponential smoothing, or machine learning models.\n",
    "\n",
    "5.  **Model Selection and Evaluation**: Rigorous model selection and evaluation are essential to ensure the chosen model generalizes well to unseen data.\n",
    "\n",
    "    -   **Time Series Cross-Validation**: Unlike traditional cross-validation, time series cross-validation respects the temporal order of the data. Techniques like rolling-origin cross-validation are used to simulate forecasting at different points in time.\n",
    "\n",
    "    -   **Evaluation Metrics**: Assess model performance using appropriate metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), or Mean Absolute Percentage Error (MAPE).\n",
    "\n",
    "    -   **Statistical Significance Tests**: When comparing multiple models, statistical tests can help determine if the differences in performance are statistically significant.\n",
    "\n",
    "6.  **Fit Parameters**: Once a model is selected, its parameters must be estimated using the training data.\n",
    "\n",
    "    -   This often involves optimization techniques to minimize the chosen error metric.\n",
    "\n",
    "7.  **Model Validation**: After training, it's crucial to validate the model on a separate validation set to ensure it generalizes well and is not overfitting.\n",
    "\n",
    "8.  **Forecasting**: With a validated model, forecasts can be generated for the desired future time periods.\n",
    "\n",
    "9.  **Uncertainty Estimation**: Providing forecasts without an estimate of their uncertainty can be misleading.\n",
    "\n",
    "    -   Techniques like prediction intervals, bootstrapping, or simulation can be used to quantify the range of possible future outcomes.\n",
    "\n",
    "10. **Monitoring and Model Updating**: Forecasting models should be continuously monitored and updated as new data becomes available.\n",
    "\n",
    "    -   The performance of the model may degrade over time due to changes in the underlying patterns of the time series.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3d8a4-b5bc-4cc3-a604-8db21e16fb02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## II.2. Naïve forecasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bd16c-7b59-48c6-ac44-2e32162e5bc0",
   "metadata": {},
   "source": [
    "We introduce some basic, yet important, forecasting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef44fb-43e1-4fe3-b1c2-9bacb6787958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.datasets import load_airline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71da46e-0a00-45a7-aaba-731bf7ad3bba",
   "metadata": {},
   "source": [
    "#### II.2.A. Naïve average method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c7dc5-7ba0-4c34-af1d-6855b9103b67",
   "metadata": {},
   "source": [
    "The average method forecasts all future values as the mean of the historical data.\n",
    "\n",
    "$$\n",
    "\\hat{y}_t = \\bar{y} = \\frac{1}{T} \\sum_{t=1}^{T} y_t\n",
    "$$\n",
    "\n",
    "where $\\hat{y}_t$ is the forecast at time $t$, $\\bar{y}$ is the mean of the historical data, and $T$ is the number of historical data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a583a89-3116-43be-939e-fb123e653eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"mean\")\n",
    "forecaster.fit(y)\n",
    "\n",
    "fh = ForecastingHorizon(values=range(1,10), is_relative=True)\n",
    "y_mean_pred = forecaster.predict(fh)\n",
    "\n",
    "fig, ax = plot_series(y, y_mean_pred, labels=[\"actual\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b079f2-4ce2-42f4-8b0a-e9800aaa2fa2",
   "metadata": {},
   "source": [
    "### II.2.B. Naïve last-value method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c8d79f-12df-4dcf-8b57-50a3c6a1cd9e",
   "metadata": {},
   "source": [
    "The naive forecaster predicts the next value to be equal to the last observed value.\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t} = y_{t-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50d4ad-daeb-433b-a672-828f76430418",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"last\")\n",
    "forecaster.fit(y)\n",
    "\n",
    "fh = ForecastingHorizon(values=range(1,10), is_relative=True)\n",
    "y_naive_pred = forecaster.predict(fh)\n",
    "\n",
    "fig, ax = plot_series(y, y_naive_pred, labels=[\"actual\", \"naive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a5071-4991-458a-abb5-ff970f49de53",
   "metadata": {},
   "source": [
    "### II.2.C. Seasonal naïve method\n",
    "\n",
    "The seasonal naive forecaster predicts the next value to be equal to the value from the same season in the previous cycle.\n",
    "\n",
    "$$\n",
    "\\hat{y}_t = y_{t-m}\n",
    "$$\n",
    "\n",
    "where $m$ is the seasonal period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87111152-2cae-40d4-863b-689f5c117b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "forecaster.fit(y)\n",
    "\n",
    "fh = ForecastingHorizon(values=range(1,10), is_relative=True)\n",
    "y_snaive_pred = forecaster.predict(fh)\n",
    "\n",
    "fig, ax = plot_series(y, y_snaive_pred, labels=[\"actual\", \"snaive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d0568-1797-4e8f-96c7-0b5a78f96a84",
   "metadata": {},
   "source": [
    "### II.2.D. Naïve drift method\n",
    "\n",
    "The drift method is a variation of the naive method that allows the forecast to increase or decrease over time.\n",
    "\n",
    "$$\\hat{y}_t = y_{t-1} + \\frac{y_{t-1} - y_{t-k}}{k}\n",
    "$$where $k$ is the number of periods over which the drift is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80e680-dcd0-46b5-b2da-8b99b136e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "# `k` would be regulated via `window_length` parameter\n",
    "forecaster = NaiveForecaster(strategy=\"drift\")\n",
    "forecaster.fit(y)\n",
    "\n",
    "fh = ForecastingHorizon(values=range(1,10), is_relative=True)\n",
    "y_drift_pred = forecaster.predict(fh)\n",
    "\n",
    "fig, ax = plot_series(y, y_drift_pred, labels=[\"actual\", \"drif\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886517bc-7ea9-4815-901e-2a94d42b72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [y, y_mean_pred, y_naive_pred, y_snaive_pred, y_drift_pred]\n",
    "labels = [\"actual\", \"mean\", \"naive\", \"snaive\", \"drift\"]\n",
    "fig, ax = plot_series(*series, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06521d-d219-4ed3-a1c9-2c3f1c4a7c85",
   "metadata": {},
   "source": [
    "### II.2.E Forecast error\n",
    "\n",
    "The forecast error ($e_t$) is the difference between the actual value ($y_t$) and the forecast value ($\\hat{y}_t$):\n",
    "\n",
    "$$\n",
    "e_t = y_t - \\hat{y}_t\n",
    "$$\n",
    "\n",
    "Residuals are useful in checking whether a model has adequately captured the information in the data.\n",
    "\n",
    "A good forecasting method will yield residuals with the following properties:\n",
    "\n",
    "- The **residuals are uncorrelated**. If there are correlations between residuals, then there is information left in the residuals which should be used in computing forecasts.\n",
    "\n",
    "- The **residuals have zero mean**. If the residuals have a mean other than zero, then the forecasts are biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437588f-244a-499c-a6d5-5b6518b035af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2d077-399b-4e73-85d6-292f91c8528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"last\")\n",
    "forecaster.fit(y)\n",
    "\n",
    "# Forecast for the entire historical period\n",
    "fh = ForecastingHorizon(y.index, is_relative=False)\n",
    "y_pred = forecaster.predict(fh)\n",
    "\n",
    "fig, ax = plot_series(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f3644-ef73-47ba-ac2d-3a93c2483bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y - y_pred\n",
    "plot_residuals(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572daa9d-c514-47e1-99de-c6c680b7c95d",
   "metadata": {},
   "source": [
    "### Assessing normality of residuals: Visual criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099a3aa-db7e-4f53-8663-81c81e617e9a",
   "metadata": {},
   "source": [
    "Normality of residuals is an important assumption for some time series analyses. Visual methods help to quickly assess deviations from normality.\n",
    "\n",
    "**Histogram:**\n",
    "\n",
    "   -   **Symmetry:** The histogram should be approximately symmetric, resembling a bell curve.\n",
    "   -   **Skewness:**\n",
    "        -   Right-skewed (long tail to the right): Indicates more smaller residuals.\n",
    "        -   Left-skewed (long tail to the left): Indicates more larger residuals.\n",
    "   -   **Kurtosis:**\n",
    "        -   Mesokurtic: Similar tail behavior to a normal distribution.\n",
    "        -   Leptokurtic: Heavier tails (more extreme residual values).\n",
    "        -   Platykurtic: Lighter tails (fewer extreme residual values).\n",
    "   -   **Normal Curve Fit:** Compare the histogram's shape to an overlaid normal distribution curve; a close fit suggests normality.\n",
    "\n",
    "**Q-Q Plot (Quantile-Quantile Plot):**\n",
    "\n",
    "   -   **Linearity:** Residuals should fall closely along the straight diagonal line.\n",
    "   -   **Deviations:**\n",
    "        -   End deviations: Indicate non-normality in the distribution's tails (skewness/kurtosis).\n",
    "        -   Curvature: Suggests skewness.\n",
    "        -   S-shape: Often indicates skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff4125-0789-4c12-ae8f-b9f7035309f2",
   "metadata": {},
   "source": [
    "**Note**: Perfect normality is rare in practice. The severity of deviations and their impact on the analysis should be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f660a633-6be4-4f12-8dd0-8da5483c1214",
   "metadata": {},
   "source": [
    "**General guideline**: Minor wiggles around the line in a `Q-Q plot are common, especially with smaller sample sizes. Focus on systematic and significant deviations. The Q-Q plot is often considered a more reliable visual tool for assessing normality than a histogram, particularly for detecting deviations in the tails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae47772-f904-4518-abf7-6dd53614a050",
   "metadata": {},
   "source": [
    "### II.2.F Bootstrapping for uncertainty estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45af1d0-0a8a-4826-b1be-b1dadba88de1",
   "metadata": {},
   "source": [
    "Bootstrapping is a resampling technique used to estimate the uncertainty of forecasts. It provides a way to generate prediction intervals without relying on strong distributional assumptions about the residuals.\n",
    "\n",
    "The process involves:\n",
    "\n",
    "1.  Fitting a forecasting model to the historical time series data.\n",
    "\n",
    "2.  Calculating the residuals.\n",
    "\n",
    "3.  Repeatedly resampling the residuals with replacement to create multiple **bootstrapped** residual sets.\n",
    "\n",
    "4.  For each bootstrapped residual set, generating a new set of forecasts by adding the resampled residuals to the model's point forecasts.\n",
    "\n",
    "5.  Calculating statistics (e.g., quantiles) across the bootstrapped forecasts to estimate prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20bab02-a7f8-4bfc-928c-03c3600d5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BootstrappedForecaster, plot_forecast_with_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729df6b5-0440-4f79-8b44-2f735515af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=10)\n",
    "forecaster.fit(y)\n",
    "\n",
    "# Forecast for the entire historical period\n",
    "fh = ForecastingHorizon(range(1,20))  \n",
    "\n",
    "y_pred, boot_preds = BootstrappedForecaster(forecaster).predict(y, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41b9d7-fd11-4b0b-97d7-131b3e14cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast_with_intervals(\n",
    "    actual=y,\n",
    "    forecast=y_pred,\n",
    "    lower=boot_preds.quantile(0.025, axis=1),\n",
    "    upper=boot_preds.quantile(0.975, axis=1),\n",
    "    title=\"Forecast airline passengers with bootstrapping\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb68c5-ca0c-417c-bb67-ff25cea72ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = energy_month[\"energy\"].asfreq(\"h\")\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=24)\n",
    "forecaster.fit(y)\n",
    "\n",
    "fh = ForecastingHorizon(range(1,24), is_relative=True)\n",
    "\n",
    "y_pred, boot_preds = BootstrappedForecaster(forecaster).predict(y, fh)\n",
    "\n",
    "plot_forecast_with_intervals(\n",
    "    actual=y[-24*8:],\n",
    "    forecast=y_pred,\n",
    "    lower=boot_preds.quantile(0.025, axis=1),\n",
    "    upper=boot_preds.quantile(0.975, axis=1),\n",
    "    title=\"Forecast energy demand with bootstrapping\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e602b5d4-c51b-4f2e-a2b5-fcf40a7565b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## II.3. Interlude: Basic transformations and adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff378e-fa72-4685-8afa-a9b93e5a5712",
   "metadata": {},
   "source": [
    "Before applying forecasting models, it is often necessary to preprocess the data through transformations and adjustments. The primary goals of these operations are to:\n",
    "- **Stabilize the variance**, i.e., to make the distribution of the series more **normal-like**,\n",
    "- account for **external factors** that are not part of the underlying pattern of the time series itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f7403-cb2f-4291-8b59-8e98e385ba24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### II.3.A. Mathematical Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9ac91-4381-4d02-aa7e-f6ffeaa97cf8",
   "metadata": {},
   "source": [
    "Simple mathematical transformations can often linearize relationships and stabilize variance. \n",
    "A series with a **variance that grows over time** can be difficult to model. \n",
    "Applying a function like a **logarithm** or **square root** can often make the variance more constant, satisfying assumptions for many classical models.\n",
    "\n",
    "-   **Logarithm (`log`)**: Particularly effective for series where the variance grows proportionally to the mean. It helps to stabilize the variance and linearize exponential growth trends.\n",
    "-   **Square Root (`sqrt`), Cube Root (`cbrt`)**: Milder transformations than the logarithm, useful for reducing right-skewness and stabilizing variance.\n",
    "-   **Inverse (`1/y`)**: A strong transformation, not as commonly used in forecasting but can be useful in specific contexts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042ec58-a728-4d27-9bcf-fd2b465912e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1032c73-483d-4d1f-bc6c-08698dd66577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "for ax, y_ts, opts in zip(\n",
    "    axes,\n",
    "    [y, np.log(y), np.sqrt(y)],\n",
    "    [\n",
    "        {\"label\": r'Original: $y$'}, \n",
    "        {\"label\": r'Transformed: $\\log(y)$', \"color\": \"red\"}, \n",
    "        {\"label\": r'Transformed: $\\sqrt{y}$', \"color\": \"purple\"},\n",
    "    ],\n",
    "):\n",
    "    ax.plot(y_ts.values, **opts)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92726fe5-20df-4b05-8b85-12d55a237e56",
   "metadata": {},
   "source": [
    "#### Box-Cox transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d266fa-af17-4697-962e-f4ed7d2b4d75",
   "metadata": {},
   "source": [
    "The Box-Cox transformation is a **more powerful** and **generalized** power transformation that automatically finds an optimal parameter, $\\lambda$ (lambda), to transform a series. Its goal is to find the best transformation to make the data more closely resemble a normal distribution and to stabilize its variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd30f0-a11d-4428-aa47-0f9cf154cf4d",
   "metadata": {},
   "source": [
    "The transformation is defined as:\n",
    "$$\n",
    "y^{(\\lambda)} = \n",
    "\\begin{cases}\n",
    "\\ln(y) & \\text{if } \\lambda = 0,\\\\\n",
    "\\frac{y^\\lambda - 1}{\\lambda} & \\text{if } \\lambda \\neq 0. \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e279011-dbaa-441e-a70e-2939f6926fec",
   "metadata": {},
   "source": [
    "We can implement our own transformer, and use it, as presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b6eb0-6fff-4a9a-8761-010486146b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MyBoxCoxTransformer\n",
    "\n",
    "y = load_airline()\n",
    "\n",
    "bc_transformer = MyBoxCoxTransformer()\n",
    "y_transformed_optimal = bc_transformer.fit_transform(y)\n",
    "\n",
    "print(f\"\\nOptimal Lambda found by scipy: {bc_transformer.alpha:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b0d1a-4218-4eca-9c5a-6e3dc15f53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 5), sharex=True)\n",
    "\n",
    "axes[0].plot(y.values, color=\"blue\")\n",
    "axes[1].plot(y_transformed_optimal, color=\"red\")\n",
    "axes[2].plot(bc_transformer.inverse_transform(y_transformed_optimal), color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7560be-4133-4056-a251-caeed51e12d5",
   "metadata": {},
   "source": [
    "One of the peculiarities of time-series transformations is that if we train a model using a transformed series, we will **need to invert the transformations** carried out, and that can be non-trivial. This is one of the reasons to introduce `sktime` transformers, as we will see in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d753f4-f66a-4b34-8e1e-b0eecf2d7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lambda_values = [-1.0, 0.0, 0.28, 0.5, 1.0]\n",
    "labels = [\n",
    "    r'Lambda = -1.0 ($y ^{-1}$)',\n",
    "    r'Lambda = 0.0 ($\\log(y)$)',\n",
    "    f'Lambda = {bc_transformer.alpha:.2f} (Optimal)',\n",
    "    r'Lambda = 0.5 ($\\sqrt{y}$)',\n",
    "    r'Lambda = 1.0 ($y$)'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(len(lambda_values), 1, figsize=(10, 15), sharex=True)\n",
    "fig.suptitle(r'Effect of $\\lambda$ values in Box-Cox transformation', fontsize=12)\n",
    "\n",
    "for i, value in enumerate(lambda_values):\n",
    "    y_transformed = MyBoxCoxTransformer(alpha=value).transform(y)\n",
    "    axes[i].plot(y_transformed, label=labels[i])\n",
    "    axes[i].legend(loc='upper left')\n",
    "    axes[i].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c9775-5e96-4d1d-ae3e-8cb3f4765ffb",
   "metadata": {},
   "source": [
    "#### Time series transformers with `sktime`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d64112-d385-4d63-9a3f-e6c972b98dd2",
   "metadata": {},
   "source": [
    "We can use pre-built transformers which are already tested in the same way we do with `sklearn` transformers.\n",
    "**Scikit Time** (or `sktime`) comes with a [bunch of transformers](https://www.sktime.net/en/stable/examples/03_transformers.html) (built-in and tested thoroughly!) so that we do not have to code them by ourselves. Also with the convenience that they will be very easily integrated in forecasting pipelines, as we will see later. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a010e1-2041-4dd0-93ac-22a6f9afcba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.boxcox import BoxCoxTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ff684-637f-46e8-9c7b-996645ffd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(lambda_values), 1, figsize=(10, 15), sharex=True)\n",
    "fig.suptitle(r'Effect of $\\lambda$ values in Box-Cox transformation', fontsize=12)\n",
    "\n",
    "for i, l in enumerate(lambda_values):\n",
    "    transformer = BoxCoxTransformer(method=\"fixed\",  lambda_fixed=l)\n",
    "    y_transformed = transformer.fit_transform(y)\n",
    "    axes[i].plot(y_transformed.values, label=labels[i])\n",
    "    axes[i].legend(loc='upper left')\n",
    "    axes[i].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a7f02-7498-45b2-a90f-24d25b8bdeec",
   "metadata": {},
   "source": [
    "### II.3.B. Calendar Adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1fd18-09d0-4e82-b292-dcdf7da30891",
   "metadata": {},
   "source": [
    "Sometimes, variations in a time series are due to systemic, calendar, or economic effects rather than the underlying pattern of interest. Adjusting for these can lead to better forecasts.\n",
    "\n",
    "Data aggregated over months can be misleading because months have different numbers of days (from 28 to 31). This can introduce artificial variation. This effect can be corrected by adjusting the data to represent an average month's length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760a2ef-82c0-4833-9658-ef24498c5e6d",
   "metadata": {},
   "source": [
    "#### Example: Adjusting monthly electricity consumption - scale the consumption by the number of days in month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7bb118-bc43-4a4d-9564-3cfaab6d21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "monthly_demand = ExampleDataLoader(\"monthly_demand\").load()\n",
    "monthly_demand.set_index([\"Date\"], inplace=True)\n",
    "\n",
    "fig, ax = plot_series(monthly_demand[\"Demand\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34f68f-58ac-49e8-bc8f-ce2b37f1916f",
   "metadata": {},
   "source": [
    "##### Manual adjustment (prone to future errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433aa8e-1b2f-47c2-9363-40e8f4e85679",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_demand.reset_index(names=[\"Date\"], inplace=True)\n",
    "\n",
    "monthly_demand[\"DaysInMonth\"] = monthly_demand[\"Date\"].dt.days_in_month\n",
    "avg_days_per_month = 365.25 / 12\n",
    "monthly_demand[\"AdjustedDemand\"] = (monthly_demand[\"Demand\"] / monthly_demand[\"DaysInMonth\"]) * avg_days_per_month\n",
    "\n",
    "monthly_demand.set_index([\"Date\"], inplace=True)\n",
    "fig, ax = plot_series(monthly_demand[\"AdjustedDemand\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc15abc-4e25-4ab3-ab80-384dd86cf17d",
   "metadata": {},
   "source": [
    "##### Using custom Time Series transfomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12757d6-0df8-4235-a841-dd8be223b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MyMonthlyAdjuster\n",
    "\n",
    "monthly_demand = ExampleDataLoader(\"monthly_demand\").load()\n",
    "monthly_demand.set_index([\"Date\"], inplace=True)\n",
    "\n",
    "fig, ax = plot_series(MyMonthlyAdjuster().fit_transform(monthly_demand))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a81b9-9701-4899-b3c4-ec4ba0b41388",
   "metadata": {},
   "source": [
    "### II.3.C. Economic Adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f09aa29-5a5f-4a2e-a371-aae07a987716",
   "metadata": {},
   "source": [
    "Some useful adjustments needed when dealing with economic data are (amongst many others):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691cf3d1-9add-4128-8c1a-9ee2d187c1a9",
   "metadata": {},
   "source": [
    "#### Inflation\n",
    "\n",
    "When forecasting series involving monetary values (e.g., prices, revenue), it is crucial to account for inflation. This is done by deflating the series with a price index (like the Consumer Price Index, CPI) to get values in \"real\" or \"constant\" terms.\n",
    "\n",
    "$$\\text{real\\_value} = (\\text{nominal\\_value} / \\text{price\\_index}) * 100$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edd14a-3f5a-41df-98df-52f606b8eafd",
   "metadata": {},
   "source": [
    "#### Population Growth\n",
    "\n",
    "For series influenced by population size (e.g., number of public transport users, total sales of a product), it is often better to forecast a **per-capita** value. This removes the variation simply caused by a changing population.\n",
    "\n",
    "  \n",
    "$$\\text{per\\_capita\\_value} = \\text{total\\_value} / \\text{population}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2ac24-dd41-4aae-8b6c-9baeade937b6",
   "metadata": {},
   "source": [
    "Beyond inflation and population, several other external factors can distort the underlying patterns in economic data. Adjusting for these effects is a crucial step in building accurate and interpretable models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a82c4d-fa9a-4395-90ae-5e9bab08ac8f",
   "metadata": {},
   "source": [
    "#### Trading day and working day adjustment\n",
    "\n",
    "* **Concept**: Months and quarters have a varying number of trading days or working days. For example, February has fewer working days than March, and a given quarter might have more weekends than another. This can cause significant variation in production or sales data that has nothing to do with economic health.\n",
    "\n",
    "* **Example Series**: `Industrial Production`, `Exports/Imports`, `Monthly Retail Sales`.\n",
    "\n",
    "* **Method of Adjustment**:\n",
    "    * **Direct Scaling**: Divide the monthly total by the number of trading days in that month to get a \"per-day\" rate. This can then be multiplied by an average number of trading days per month to create an adjusted series.\n",
    "    * **Regression Approach**: Use the number of trading days as an explanatory variable in a regression model (like ARIMA with regressors, known as REGARIMA). The model will estimate the effect of an additional trading day and effectively account for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03494da-791b-424d-acdf-2098f064d062",
   "metadata": {},
   "source": [
    "#### Holiday effects\n",
    "\n",
    "* **Concept**: While fixed holidays like Christmas contribute to standard seasonality, **moving holidays** like Easter can create major analytical challenges. Easter can fall in either March (Q1) or April (Q2), shifting a significant amount of economic activity (e.g., retail sales, travel) between quarters from one year to the next.\n",
    "  \n",
    "* **Example Series**: `Retail Sales` (especially for candy, clothing), `Tourist Arrivals`, `Air Passenger Traffic`.\n",
    "\n",
    "  \n",
    "* **Method of Adjustment**:\n",
    "    * **Dummy/Indicator Variables**: Create a dummy variable that is `1` for the period affected by the moving holiday (e.g., the 7 days leading up to Easter) and `0` otherwise. This variable can then be included as a regressor in the model to capture the holiday's specific impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c4910-a088-4732-8333-a7b3b334763b",
   "metadata": {},
   "source": [
    "#### Exchange rate adjustment\n",
    "\n",
    "* **Concept**: For any data involving international transactions, fluctuations in currency exchange rates can obscure underlying business performance. A company's revenue from foreign sales might increase in its home currency simply because the foreign currency strengthened, even if sales volume was flat.\n",
    "\n",
    "* **Example Series**: `Export/Import Values`, `Revenue of a Multinational Corporation`, `Foreign Direct Investment (FDI)`.\n",
    "\n",
    "* **Method of Adjustment**:\n",
    "    * **Constant Exchange Rate**: Convert all foreign currency amounts to a single home currency using a constant exchange rate, typically the average rate from a fixed base year. This removes the effect of currency volatility.\n",
    "    * **Analyze in Local Currency**: Analyze performance within a country or region in its own local currency before aggregating results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd306869-45d8-4c46-a3e6-2dafcd60b4f4",
   "metadata": {},
   "source": [
    "#### Seasonal adjustment\n",
    "\n",
    "* **Concept**: This is a fundamental and widespread adjustment in economics. It goes beyond just modeling seasonality and involves removing the seasonal component entirely to better highlight the underlying trend-cycle of the series. Most major government economic statistics (like GDP or unemployment) are presented in a seasonally adjusted (SA) form.\n",
    "    \n",
    "* **Example Series**: `Gross Domestic Product (GDP)`, `Unemployment Rate`, `Housing Starts`.\n",
    "    \n",
    "* **Method of Adjustment**:\n",
    "    * **Standardized Programs**: Use well-established statistical programs like **X-13-ARIMA-SEATS** (developed by the U.S. Census Bureau) or methods like **STL Decomposition**. These are sophisticated methods that can handle various types of seasonality and calendar effects simultaneously.\n",
    "    * `sktime` and other libraries provide interfaces to some of these methods (e.g., via `statsmodels`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c3ae6-49c0-4cd6-97e9-88be168a8a23",
   "metadata": {},
   "source": [
    "#### Adjustment for policy changes and structural breaks\n",
    "\n",
    "* **Concept**: Economic series can change fundamentally due to external events that alter the \"rules of the game.\" This is known as a structural break. Examples include a new tax law, a change in interest rate policy, a new trade agreement, or deregulation.\n",
    "\n",
    "* **Example Series**: `Tax Revenue` before and after a tax cut, `Trade Volume` with a country after a new tariff is imposed, `Loan Applications` after a central bank policy change.\n",
    "\n",
    "* **Method of Adjustment**:\n",
    "    * **Intervention Analysis**: Use dummy variables to model the effect. A **step dummy** (0 before the event, 1 after) can model a permanent level shift. A **pulse dummy** (1 only at the time of the event, 0 otherwise) can model a temporary shock.\n",
    "    * **Segmented Modeling**: Split the time series into two or more segments (before and after the break) and model each segment separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac046e65-2527-4cdb-847c-e0a8f08c209e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## II.4. Simple decomposition methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbf4a9-863c-44a2-96e1-a1fd4d766fa7",
   "metadata": {},
   "source": [
    "Time series decomposition is a fundamental technique used to deconstruct a time series into several constituent components. By separating the series into its parts, we can better understand its underlying structure, identify patterns, and produce a seasonally adjusted series for further analysis or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc08ee-a583-4d8e-9b68-fde7c418c121",
   "metadata": {},
   "source": [
    "### II.4.A. What is decomposition?\n",
    "\n",
    "The core idea is to model the observed time series $y_t$ as a function of three key components:\n",
    "\n",
    "1.  **Trend-Cycle ($\\tau_t$)**: The long-term direction or underlying trend of the series. This component captures the slow-moving, non-periodic changes.\n",
    "2.  **Seasonal ($\\sigma_t$)**: The periodic fluctuations that occur at fixed intervals, such as daily, monthly, or quarterly patterns.\n",
    "3.  **Irregular or Residual ($\\epsilon_t$)**: The leftover random noise or error component that is not explained by the trend and seasonal components.\n",
    "\n",
    "\n",
    "The general relationship is expressed as:\n",
    "$$\n",
    "y_t = f(\\tau_t, \\sigma_t, \\epsilon_t)\n",
    "$$\n",
    "\n",
    "This approach is based on the hypotheses that the series contains: \n",
    "\n",
    "- an identifiable long-term **trend**,\n",
    "- exhibits some form of regular **periodicity** (seasonality),\n",
    "- and that these systematic components can be separated from irregular noise (uncertainty)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263c030-7b32-4825-bc75-bb0ac1d27b42",
   "metadata": {},
   "source": [
    "### II.4.B. Types of decomposition models\n",
    "\n",
    "The way the components are combined defines the type of decomposition model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c88a0-d2ee-439e-9ce7-3a1f16f5eb9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Additive Model\n",
    "The components are summed together. This model is appropriate when the magnitude of the seasonal fluctuations **does not** vary with the level of the time series.\n",
    "\n",
    "$$\n",
    "y_t = \\tau_t + \\sigma_t + \\epsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae72c2-c8db-4da7-98d7-c75b7c5432b4",
   "metadata": {},
   "source": [
    "#### Multiplicative Model\n",
    "The components are multiplied. This is very common in economic series, where the seasonal variation tends to increase as the level of the series rises.\n",
    "\n",
    "$$\n",
    "y_t = \\tau_t \\times \\sigma_t \\times \\epsilon_t\n",
    "$$\n",
    "\n",
    "A key property of the multiplicative model is that it can be transformed into an additive one by taking the natural logarithm:\n",
    "$$\n",
    "\\log(y_t) = \\log(\\tau_t) + \\log(\\sigma_t) + \\log(\\epsilon_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a8e07-4da9-4c74-8eca-6b15604cfc7c",
   "metadata": {},
   "source": [
    "#### Pseudo-additive (hybrid) model\n",
    "\n",
    "This model combines multiplicative and additive elements, for instance, when a trend is multiplicative but the seasonality is additive around it.\n",
    "$$\n",
    "y_t = \\tau_t \\times (\\sigma_t + \\epsilon_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e421b5-2acd-4b0e-bb73-dbb5cc1ae1af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example: Additive decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c8dca7-6f0f-4226-8351-c65aad119d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff45c02e-ef4e-422c-b0ea-bdb25281d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f7fb-91f0-4e1a-bf5c-59b55f492bed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Manual decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd6948-ffac-444b-bffe-6789c54b8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "# Trend:\n",
    "trend_forecaster = PolynomialTrendForecaster(degree=1)\n",
    "detrender = Detrender(forecaster=trend_forecaster)\n",
    "trend = trend_forecaster.fit(y).predict(fh=y.index)\n",
    "\n",
    "y_detrended = detrender.fit_transform(y)\n",
    "\n",
    "# Seasonality:\n",
    "deseasonalizer = Deseasonalizer(sp=12, model=\"additive\")\n",
    "seasonality = y_detrended - deseasonalizer.fit_transform(y_detrended)\n",
    "\n",
    "# Residual:\n",
    "residual = y - (trend + seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf98869-b6e7-47e7-ba24-559d764feca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plot_decomposition(y, trend=trend, seasonality=seasonality, residual=residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1dc056-90ca-4937-b728-a6d55c1347b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2f4fc-7ba9-437a-8568-fb42a96cbe3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c2531-f2ae-48f6-a4ce-20ed57e23b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.compose import TransformerPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785ac7d-5708-4d64-8276-4c30013c62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "pipe = TransformerPipeline(steps=[\n",
    "    (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
    "    (\"deseasonalize\", Deseasonalizer(model=\"additive\", sp=12)),\n",
    "])\n",
    "\n",
    "residual = pipe.fit_transform(y)\n",
    "\n",
    "# Get trend\n",
    "detrender = pipe.steps_[0][1]\n",
    "y_detrended = detrender.transform(y)\n",
    "trend = y - y_detrended\n",
    "\n",
    "# seasonality:\n",
    "deseasonalizer = pipe.steps_[1][1]\n",
    "seasonality = y_detrended - deseasonalizer.transform(y_detrended)\n",
    "\n",
    "# Residual:\n",
    "residual = y - (trend + seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e868e75-d2bc-4010-96cd-1a8af8c53485",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plot_decomposition(y, trend=trend, seasonality=seasonality, residual=residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d574ae6-bf36-4c9d-bb3b-a51204b5b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e594256-5f1d-4020-bd06-c2723458153e",
   "metadata": {},
   "source": [
    "#### Example: Multiplicative decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee807c7-89d9-4f62-9e2c-599738b9db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "# trend \n",
    "trend_forecaster = PolynomialTrendForecaster(degree=1)\n",
    "detrender = Detrender(forecaster=trend_forecaster)\n",
    "trend = trend_forecaster.fit(y).predict(fh=y.index)\n",
    "y_detrended = y / trend\n",
    "\n",
    "# Seasonality\n",
    "deseasonalizer = Deseasonalizer(sp=12, model=\"multiplicative\")\n",
    "seasonality = y_detrended / deseasonalizer.fit_transform(y_detrended)\n",
    "\n",
    "# Residual\n",
    "residual = y / (trend * seasonal_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66505b64-5ae3-435c-a610-8d61539c930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plot_decomposition(y, trend=trend, seasonality=seasonality, residual=residual, model=\"multiplicative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33ff08-08eb-408b-8be6-984e4df39664",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee74715-699f-4ef8-a80b-7e062806207c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Other advanced decomposition methods: X-11 and SEATS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3472d5eb-b000-4825-85d8-6fa34b8964db",
   "metadata": {},
   "source": [
    "Classical decomposition is a simple and useful exploratory tool, but it has drawbacks:\n",
    "\n",
    "- The trend estimate is unavailable for the first and last few data points.\n",
    "- It assumes the seasonal component repeats exactly from year to year.\n",
    "- It is sensitive to outliers.\n",
    "\n",
    "More advanced methods have been developed to overcome these issues, with [X-13-ARIMA-SEATS](https://www.census.gov/data/software/x13as.html) (from the US Census Bureau) and [TRAMO-SEATS](https://es.wikipedia.org/wiki/TRAMO-SEATS) (from the **Bank of Spain**) being the industry standard for official statistics.\n",
    "\n",
    "**Key advantages** of these methods include:\n",
    "\n",
    "- Better End-Point Handling: They \"recover\" the lost data at the ends of the trend component.\n",
    "- Evolving Seasonality: The seasonal component is allowed to change gradually over time.\n",
    "- Robustness: They can handle calendar effects (trading days, moving holidays) and outliers as part of the decomposition process.\n",
    "\n",
    "These methods are available through `statsmodels` and can be integrated into an `sktime` workflow for more robust seasonal adjustment and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9155e2ec-b93f-4923-b413-9d650c7932fa",
   "metadata": {},
   "source": [
    "#### Automated with STL: Seasonal and trend decomposition using Loess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bfec12-3713-4b3c-8c85-dbb79fc08de4",
   "metadata": {},
   "source": [
    "\n",
    "STL is a versatile and robust method for decomposing a time series into its trend, seasonal, and residual components. It was developed by R. B. Cleveland et al. and represents a significant advancement over classical decomposition methods. The name \"STL\" is an acronym for \"Seasonal and Trend decomposition using Loess,\" where Loess is the key to its flexibility.\n",
    "\n",
    "STL can handle any type of seasonality (not just monthly or quarterly) and the seasonal component is allowed to change over time. Its most significant advantage comes from the use of **Loess** (Locally Estimated Scatterplot Smoothing), a non-parametric regression method.\n",
    "\n",
    "Instead of fitting a single polynomial to the entire dataset to find the trend, Loess fits numerous simple linear models on small, localized subsets of the data. This allows it to capture complex and changing patterns without making rigid assumptions about the data's underlying structure.\n",
    "\n",
    "Key advantages of STL include:\n",
    "* **Robustness to outliers**: STL includes an outer loop that iteratively calculates \"robustness weights\" to reduce the influence of outliers on the final decomposition.\n",
    "* **Flexibility**: It can decompose series with complex or changing seasonal patterns.\n",
    "* **Control**: The user can control the smoothness of the trend and the rate of change in the seasonal component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9ffb4-1203-48af-bb63-31d8a4a06e68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Bonus: An intuitive overview of the STL algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee478deb-1883-4e0b-b98d-00b854f62106",
   "metadata": {},
   "source": [
    "STL uses a two-loop procedure:\n",
    "\n",
    "1.  **The Inner Loop**: Iteratively separates the trend and seasonal components.\n",
    "    * **(a) Detrending**: An initial trend estimate is subtracted from the series.\n",
    "    * **(b) Cycle-Subseries Smoothing**: The detrended series is broken down into seasonal sub-series (e.g., all the January values, all the February values, etc.). Loess is then applied to smooth each of these sub-series.\n",
    "    * **(c) Filtering**: The collection of smoothed sub-series is filtered to produce the final seasonal component for this iteration.\n",
    "    * **(d) Detrending again**: The seasonal component is subtracted from the original series, and Loess is applied to smooth the result to find the trend component for this iteration.\n",
    "\n",
    "2.  **The Outer Loop**: This is what provides robustness.\n",
    "    * After an inner loop completes, the residuals ($y_t - \\tau_t - \\sigma_t$) are calculated.\n",
    "    * Large residuals (potential outliers) are identified, and \"robustness weights\" are calculated for each data point. Points with large residuals are given small (or zero) weights.\n",
    "    * The entire inner loop is then repeated, but this time the Loess smoothing steps use these weights, effectively downplaying the influence of outliers. This outer loop is typically repeated a few times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379c9cc-2f46-4496-85d4-d57d0133658c",
   "metadata": {},
   "source": [
    "##### Example: Decomposing atmospheric CO2 from continuous air samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95097f66-f197-48fc-8038-272987f1b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.transformations.series.detrend import STLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8dd60-4ef3-4752-98a4-090f7442fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.datasets import co2\n",
    "\n",
    "y = co2.load().data.resample('ME').mean().ffill()\n",
    "\n",
    "transformer = STLTransformer(sp=12, return_components=True)  \n",
    "y_t = transformer.fit_transform(y)  \n",
    "\n",
    "fig, ax = plot_series(y)\n",
    "ax.plot(y_t.trend + y_t.seasonal, color=\"purple\", linestyle=\"-.\", label=\"Reconstruction\")\n",
    "ax.plot(y_t.trend, color=\"red\", linestyle=\"--\", alpha=0.6, label=\"Trend\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f403a-00d8-4f1d-825d-a9f7a331f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(y_t.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f17459-7364-4d00-960e-fd40aaca017c",
   "metadata": {},
   "source": [
    "##### Example: Decomposing Australia's electricty demand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819409bc-8089-4c20-9bbb-d2eac03d761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.detrend.mstl import MSTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97363e-2321-4618-aa31-b307a2a685dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df = ExampleDataLoader(\"electricity\").load().set_index(\"Time\")\n",
    "electricity_df.index\n",
    "\n",
    "y = plot_series_slice(\n",
    "    electricity_df[\"Demand\"],\n",
    "    start=\"2012-02-01 00:00:00+00:00\",\n",
    "    stop=\"2012-02-28 00:00:00+00:00\",\n",
    "    freq=\"30 min\",\n",
    "    return_data=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada51a0-cb96-400f-96c8-7a8257e2e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = STLTransformer(sp=24*20, return_components=True)  \n",
    "y_t = transformer.fit_transform(y)  \n",
    "\n",
    "fig, ax = plot_series(y)\n",
    "ax.plot(y_t.trend + y_t.seasonal, color=\"purple\", linestyle=\"-.\", label=\"Reconstruction\")\n",
    "ax.plot(y_t.trend, color=\"red\", linestyle=\"--\", alpha=0.6, label=\"Trend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c781a2-2304-4409-8b57-9661a5cc795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MSTL(periods=[24, 24*7], return_components=True)\n",
    "y_t = transformer.fit_transform(y)  \n",
    "y_t.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06415fe1-673b-4f3f-b667-3b45f6a14aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
